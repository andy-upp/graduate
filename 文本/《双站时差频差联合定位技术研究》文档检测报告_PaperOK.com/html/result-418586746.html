<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
		<title>无标题文档</title>
		<link href="img/style.css" rel="stylesheet" type="text/css" media="all" />
	</head>
	<body id="shard-result">
		<div class="mainbody result">
			<strong class="title">原文句子<a href="#modifyAdvise">（查看句子修改意见）</a></strong>
			<div class="p source">
				ReLU函数的优点如下：
			</div>
			<strong class="title">片段位置图</strong>
			<p>
				<img src="img/localimg_418586746.png"/>
			</p>
			<strong class="title">相似结果</strong>
			<table class="detail">
				<tbody>
					<tr>
						<td valign="top" class="result">
										<div class="p">
											<b>相似片段 1：</b><em>优点： 1.研究者认为 ReLU 将负值部分置 0，保留正值部分的做法为模型隐含层引入了稀疏性，因此提高了模型的性能。对此，Bing Xu等[92]人有不同意见。 2.传统的饱和激活函数</em>
										</div>
										<table class="detail none" border="0">
											<tr><td width="60">篇名</td><td>《基于 LSTM的语义关系分类研究》</td></tr>
											<tr><td>对比库</td><td>
														学位论文数据库</td></tr>
															<tr><td>来源信息</td><td>
																	作者（胡新辰）
																	学校（哈尔滨工业大学）
																	分类（计算机科学与技术）
																	学位（硕士）
																	日期（2015-01-01）
															</td></tr>
																							<tr>
												<td>相似率</td>
												<td>
														75%
															<span class="autotype">（高度相似）</span>
												</td>
											</tr>
															<tr>
																<td>文献溯源</td>
																<td>
																	<span class="baiduxueshu">百度学术</span>
																	<a href="http://xueshu.baidu.com/s?wd=%E5%9F%BA%E4%BA%8E%20LSTM%E7%9A%84%E8%AF%AD%E4%B9%89%E5%85%B3%E7%B3%BB%E5%88%86%E7%B1%BB%E7%A0%94%E7%A9%B6&rsv_bp=0&tn=SE_baiduxueshu_c1gjeupa&rsv_spt=3&ie=utf-8&f=8&rsv_sug2=1&sc_f_para=sc_tasktype%3D%7BfirstSimpleSearch%7D&rsv_n=2" target="_blank" class="ml10">查看来源</a>
																</td>
															</tr>
										</table>
										<div class="p">
											<b>相似片段 2：</b>表明 softplus<em>函数比 ReLU函数效果要差[41] 。ReLU的优点有：从生物角度来讲更合理，ReLU相比非对称的 tanh 函数是单边函数</em>；稀疏性，例如在随机初始化的网络中，只有约 50
										</div>
										<table class="detail none" border="0">
											<tr><td width="60">篇名</td><td>《基于深度学习的汉语语音关键词检测方法 研究》</td></tr>
											<tr><td>对比库</td><td>
														学位论文数据库</td></tr>
															<tr><td>来源信息</td><td>
																	作者（王朝松）
																	学校（哈尔滨工业大学）
																	分类（计算机科学与技术）
																	学位（硕士）
																	日期（2015-01-01）
															</td></tr>
																							<tr>
												<td>相似率</td>
												<td>
														75%
															<span class="autotype">（高度相似）</span>
												</td>
											</tr>
															<tr>
																<td>文献溯源</td>
																<td>
																	<span class="baiduxueshu">百度学术</span>
																	<a href="http://xueshu.baidu.com/s?wd=%E5%9F%BA%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%B1%89%E8%AF%AD%E8%AF%AD%E9%9F%B3%E5%85%B3%E9%94%AE%E8%AF%8D%E6%A3%80%E6%B5%8B%E6%96%B9%E6%B3%95%20%E7%A0%94%E7%A9%B6&rsv_bp=0&tn=SE_baiduxueshu_c1gjeupa&rsv_spt=3&ie=utf-8&f=8&rsv_sug2=1&sc_f_para=sc_tasktype%3D%7BfirstSimpleSearch%7D&rsv_n=2" target="_blank" class="ml10">查看来源</a>
																</td>
															</tr>
										</table>
						</td>
					</tr>
				</tbody>
			</table>
				<a name="modifyAdvise"></a>
				<div class="p"
					style="background: #FFFFE1; border: 1px dashed #FF9797;">
					<p style="font-size: 14px; font-weight: bold;">※ 片段修改建议 ※</p>
					<b>近似词参考：</b><ul type='1'><li>优点：长处 好处 </li><li>如下：以下 </li></ul><p><b>系统自动生成语句：</b>ReLU函数的<u>长处</u><u>以下</u>：</p><p class='gray'>注：本片段修改建议为系统自动生成，仅供参考。	</p>
				</div>
		</div>
	</body>
</html>

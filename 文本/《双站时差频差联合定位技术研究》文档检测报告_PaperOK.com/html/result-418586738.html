<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
		<title>无标题文档</title>
		<link href="img/style.css" rel="stylesheet" type="text/css" media="all" />
	</head>
	<body id="shard-result">
		<div class="mainbody result">
			<strong class="title">原文句子<a href="#modifyAdvise">（查看句子修改意见）</a></strong>
			<div class="p source">
				但是它也存在梯度饱和的问题，从数学变换中可以看出，Tanh是Sigmoid的变形：
			</div>
			<strong class="title">片段位置图</strong>
			<p>
				<img src="img/localimg_418586738.png"/>
			</p>
			<strong class="title">相似结果</strong>
			<table class="detail">
				<tbody>
					<tr>
						<td valign="top" class="result">
									<div style="width:20px;height:20px;border:1px solid #ccc;line-height:20px;text-align:center;margin:10px 0px;font-size:14px;font-weight:bold;">
										1
									</div>
									<div class="p" style="background:#ccc;">
										<b>原句片段：</b>但是它也存在梯度饱和的问题，从数学变换中可以看出，Tanh是Sigmoid的变形：
									</div>
											<div class="p">
												<b>相似片段 1：</b>神经元的<em>梯度就接近于0了,从图中可以看出梯度的...但是它还是存在梯度饱和的问题。Tanh是sigmoid的变形:...作者从数学</em>的角度上也证明了这个结论,即只需2个max...
											</div>
											<table class="detail none" border="0">
												<tr><td width="60">篇名</td><td>《activationfunctions学案.doc》</td></tr>
												<tr><td>对比库</td><td>
互联网学术资源库</td></tr>																									<tr>
													<td>相似率</td>
													<td>
															84.62%
																<span class="autotype">（高度相似）</span>
													</td>
												</tr>
																<tr>
																	<td>来源</td>
																	<td>
																		<span class="cloud">云论文库</span>
																		<a href="https://max.book118.com/html/2016/1224/76388251.shtm" target="_blank" class="cloud">查看来源</a>
																	</td>
																</tr>
											</table>
											<div class="p">
												<b>相似片段 2：</b><em>但是它还是存在梯度饱和的问题。Tanh是sigmoid的变形:tanh(x)=2σ(2x)?1。 ReLU. 近年来,ReLU 变的越来越受欢迎。它的数学</em>表达式是: f(x)=max(0,x)。...
											</div>
											<table class="detail none" border="0">
												<tr><td width="60">篇名</td><td>《几种常见的激活函数 - CSDN博客》</td></tr>
												<tr><td>对比库</td><td>
互联网学术资源库</td></tr>																									<tr>
													<td>相似率</td>
													<td>
															69.23%
																<span class="light_autotype">（中度相似）</span>
													</td>
												</tr>
																<tr>
																	<td>来源</td>
																	<td>
																		<span class="cloud">云论文库</span>
																		<a href="http://blog.csdn.net/u014365862/article/details/52710698" target="_blank" class="cloud">查看来源</a>
																	</td>
																</tr>
											</table>
											<div class="p">
												<b>相似片段 3：</b><em>但是它还是存在梯度饱和的问题。Tanh是sigmoid的变形:tanh(x)=2σ(2x)?1。 ReLU. 近年来,ReLU 变的越来越受欢迎。它的数学</em>表达式是: f(x)=max(0,x)。...
											</div>
											<table class="detail none" border="0">
												<tr><td width="60">篇名</td><td>《【Stanford CNN课程笔记】5. 神经网络解读1 几种常见的激活函数》</td></tr>
												<tr><td>对比库</td><td>
互联网学术资源库</td></tr>																									<tr>
													<td>相似率</td>
													<td>
															69.23%
																<span class="light_autotype">（中度相似）</span>
													</td>
												</tr>
																<tr>
																	<td>来源</td>
																	<td>
																		<span class="cloud">云论文库</span>
																		<a href="http://blog.csdn.net/elaine_bao/article/details/50810598" target="_blank" class="cloud">查看来源</a>
																	</td>
																</tr>
											</table>
											<div class="p">
												<b>相似片段 4：</b><em>但是它还是存在梯度饱和 的问题。Tanh 是sigmoid 的变形:tanh(x)=2sigmoid(2x...作者从数学</em>的角度上也证明 了这个结论,即只需2 个maxout 节点就可以拟合任意...
											</div>
											<table class="detail none" border="0">
												<tr><td width="60">篇名</td><td>《activation functions - 豆丁网》</td></tr>
												<tr><td>对比库</td><td>
互联网学术资源库</td></tr>																									<tr>
													<td>相似率</td>
													<td>
															69.23%
																<span class="light_autotype">（中度相似）</span>
													</td>
												</tr>
																<tr>
																	<td>来源</td>
																	<td>
																		<span class="cloud">云论文库</span>
																		<a href="http://www.docin.com/p-1729085781.html" target="_blank" class="cloud">查看来源</a>
																	</td>
																</tr>
											</table>
											<div class="p">
												<b>相似片段 5：</b><em>但是它还是存在梯度饱和的问题。Tanh是sigmoid的变形:tanh(x)=2σ(2x)?1。ReLU. 近年来,ReLU 变的越来越受欢迎。它的数学</em>表达式是: f(x)=max(0,x)。很...
											</div>
											<table class="detail none" border="0">
												<tr><td width="60">篇名</td><td>《几种常见的激活函数-办公软硬件 - 就爱阅读,在线图书馆!(www....》</td></tr>
												<tr><td>对比库</td><td>
互联网学术资源库</td></tr>																									<tr>
													<td>相似率</td>
													<td>
															69.23%
																<span class="light_autotype">（中度相似）</span>
													</td>
												</tr>
																<tr>
																	<td>来源</td>
																	<td>
																		<span class="cloud">云论文库</span>
																		<a href="http://www.beijingliyi.com/bangong/2017/10-24/30392578.html" target="_blank" class="cloud">查看来源</a>
																	</td>
																</tr>
											</table>
											<div class="p">
												<b>相似片段 6：</b><em>但是它还是存在梯度饱和的问题。Tanh 是 sigmoid 的变形:tanh(x)=2...作者从数学</em>的角度上也证明了这个结论,即只需 2 个 maxout 节点就可以...
											</div>
											<table class="detail none" border="0">
												<tr><td width="60">篇名</td><td>《activation functions - 道客巴巴》</td></tr>
												<tr><td>对比库</td><td>
互联网学术资源库</td></tr>																									<tr>
													<td>相似率</td>
													<td>
															69.23%
																<span class="light_autotype">（中度相似）</span>
													</td>
												</tr>
																<tr>
																	<td>来源</td>
																	<td>
																		<span class="cloud">云论文库</span>
																		<a href="http://www.doc88.com/p-1703144278424.html" target="_blank" class="cloud">查看来源</a>
																	</td>
																</tr>
											</table>
											<div class="p">
												<b>相似片段 7：</b>Sigmoid。sigmoid非线性函数的数学公式是,函数图像如上...和sigmoid神经元一样,<em>它也存在饱和问题,但是和...优点:相较于sigmoid和tanh函数,ReLU对于随机梯度</em>下降...
											</div>
											<table class="detail none" border="0">
												<tr><td width="60">篇名</td><td>《...6层)的神经网络中用 ReLU 层训练效果会不会比tanh/sigmoid 层...》</td></tr>
												<tr><td>对比库</td><td>
互联网学术资源库</td></tr>																									<tr>
													<td>相似率</td>
													<td>
															61.54%
																<span class="light_autotype">（中度相似）</span>
													</td>
												</tr>
																<tr>
																	<td>来源</td>
																	<td>
																		<span class="cloud">云论文库</span>
																		<a href="https://www.zhihu.com/question/48931796" target="_blank" class="cloud">查看来源</a>
																	</td>
																</tr>
											</table>
						</td>
					</tr>
				</tbody>
			</table>
				<a name="modifyAdvise"></a>
				<div class="p"
					style="background: #FFFFE1; border: 1px dashed #FF9797;">
					<p style="font-size: 14px; font-weight: bold;">※ 片段修改建议 ※</p>
					<b>近似词参考：</b><ul type='1'><li>但是：可是 然则 然而 </li><li>问题：题目 </li><li>变换：变更 </li></ul><p><b>系统自动生成语句：</b><u>可是</u>它也存在梯度饱和的<u>题目</u>，从数学<u>变更</u>中可以看出，Tanh是Sigmoid的变形：</p><p class='gray'>注：本片段修改建议为系统自动生成，仅供参考。	</p>
				</div>
		</div>
	</body>
</html>
